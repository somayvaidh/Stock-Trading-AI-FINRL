{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLCIwnUjhfCb"
      },
      "source": [
        "# Setup installs & imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv51xG1BhAi7",
        "outputId": "99b99c9b-d64c-47fb-eded-8a9febe7fcfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1)\n",
            "Requirement already satisfied: wrds in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: numpy<1.27,>=1.26 in /usr/local/lib/python3.10/dist-packages (from wrds) (1.26.4)\n",
            "Requirement already satisfied: packaging<23.3 in /usr/local/lib/python3.10/dist-packages (from wrds) (23.2)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /usr/local/lib/python3.10/dist-packages (from wrds) (2.2.2)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from wrds) (2.9.9)\n",
            "Requirement already satisfied: scipy<1.13,>=1.12 in /usr/local/lib/python3.10/dist-packages (from wrds) (1.12.0)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.10/dist-packages (from wrds) (2.0.32)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.1,>=2->wrds) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.1,>=2->wrds) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.16.0)\n",
            "Requirement already satisfied: pyportfolioopt in /usr/local/lib/python3.10/dist-packages (1.5.5)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt) (1.5.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt) (2.2.2)\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt) (1.12.0)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.6.7.post1)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (2.0.14)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.9.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (3.2.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyportfolioopt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyportfolioopt) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyportfolioopt) (2024.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.1.7.post4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pyportfolioopt) (1.16.0)\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-95b9hvj3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-95b9hvj3\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 6156c42121c21fa153722c9bbf4deef3f8f79a79\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl (from finrl==0.3.6)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-vyxan_77/elegantrl_46cab076fa2c4085822c5dba34eba62b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-vyxan_77/elegantrl_46cab076fa2c4085822c5dba34eba62b\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 307b4a264b256bdb21cc481456183bc99e266be9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: ccxt<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.1.60)\n",
            "Requirement already satisfied: exchange-calendars<5,>=4 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (4.5.5)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.9.6)\n",
            "Requirement already satisfied: pyfolio<0.10,>=0.9 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.9.2)\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.5.5)\n",
            "Requirement already satisfied: ray<3,>=2 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.35.0)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.3.2)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a5 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.4.0a7)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.5.4)\n",
            "Requirement already satisfied: wrds<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.2.43)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.32.3)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.20)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.8.0)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (10.4)\n",
            "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.0.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (3.10.5)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (6.0.1)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (71.0.4)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (2024.7.4)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (43.0.0)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (1.9.4)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.2.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2024.1)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (2.0.32)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.1.1)\n",
            "Requirement already satisfied: thriftpy2!=0.5.1,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (0.5.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (3.7.1)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (2024.1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (1.12.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.13.1)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.5.5)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (1.5.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (3.15.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (1.4.1)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (14.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.14)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.11.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.8.2)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.20.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (7.0.4)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (20.26.3)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.64.1)\n",
            "Requirement already satisfied: memray in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.13.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1->finrl==0.3.6) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1->finrl==0.3.6) (3.5.0)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.29.1)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.4.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.6.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.66.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (13.8.0)\n",
            "Requirement already satisfied: shimmy~=1.3.0 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (9.4.0)\n",
            "Requirement already satisfied: autorom~=0.6.1 in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from wrds<4,>=3->finrl==0.3.6) (2.9.9)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.2.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.1)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6) (4.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (2.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (24.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (6.0.5)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (4.0.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.17.0)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.6.7.post1)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (2.0.14)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.9.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (3.2.7)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/dist-packages (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.0.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance<0.3,>=0.2->finrl==0.3.6) (0.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.8.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.8)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6) (3.0.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.4)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.0.11)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.10/dist-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.11)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.8)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.20.0)\n",
            "Requirement already satisfied: textual>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default,tune]<3,>=2->finrl==0.3.6) (0.78.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<3,>=2->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (6.4.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.64.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.24.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (2.27.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.1.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.1.7.post4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.13)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (4.9)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (0.4.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "## install required packages\n",
        "!pip install swig\n",
        "!pip install wrds\n",
        "!pip install pyportfolioopt\n",
        "## install finrl library\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfQmoUq0hFxb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv  ##creates a custom enviorunemnt known as stockstrading env designed only for stock trading\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent   ###use of reinforcement learning algorithms provided by the Stable-Baselines3 library.\n",
        "## It’s used to train, evaluate, and deploy deep reinforcement learning models.\n",
        "from stable_baselines3.common.logger import configure  ###configure function is used to set up logging for training, which helps in tracking the progress\n",
        "## and performance of the model during training.\n",
        "from finrl import config_tickers  ##is a list of stock symbols (like “AAPL” for Apple)\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
        "\n",
        "check_and_make_directories([TRAINED_MODEL_DIR])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "313ZOiSShKbq",
        "outputId": "f5e38a2f-697b-42e2-b5ee-5feac85bfa04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZwClNPchbhS"
      },
      "source": [
        "# Load the Data from Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd_XburYhZBh"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "train=train.set_index(train.columns[0])\n",
        "train.index.names=['']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Rwka2LsiBQ5"
      },
      "source": [
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS6IgN7Hicuw",
        "outputId": "a742c24b-a611-4dfc-95fc-e679cb8ac0b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je8iX-4QiJJY",
        "outputId": "933b9c9e-b303-408e-9947-9271dff5646f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 8, State Space: 81\n"
          ]
        }
      ],
      "source": [
        "stock_dimension=len(train.tic.unique())\n",
        "state_space=1+2*stock_dimension+len(INDICATORS)*stock_dimension    # state space provides the agent\n",
        "##with all the necessary information to evaluate its current situation and decide on the next action (e.g., buy, sell, hold a stock).\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwUl-nXCiLoo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fza4gNPoswzL"
      },
      "outputs": [],
      "source": [
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension   #transaction cost\n",
        "num_stock_shares = [0] * stock_dimension   ###list keeps track of the number of shares held for each stock.\n",
        "##meaning no shares are held for any stock at the beginning.\n",
        "env_kwargs={     ##variable name\n",
        "    \"hmax\":100,   #maximum number of shares\n",
        "    \"initial_amount\":1000000, # Changed \"initalization_amount\" to \"initial_amount\"\n",
        "    \"num_stock_shares\":num_stock_shares,\n",
        "    \"buy_cost_pct\":buy_cost_list,\n",
        "    \"sell_cost_pct\":sell_cost_list,\n",
        "    \"state_space\":state_space,\n",
        "    \"stock_dim\":stock_dimension,\n",
        "    \"tech_indicator_list\":INDICATORS,\n",
        "    \"action_space\":stock_dimension,\n",
        "    \"reward_scaling\":1e-4\n",
        "}\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NakislXPiSL2"
      },
      "source": [
        "### Environment for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUP0u55fiOXu",
        "outputId": "8a54b0c0-a7db-4acc-c673-f8cffe8a5ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        }
      ],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()   ###onverts your custom environment(ENVKAWRDS CONVERTED TO E_TRAIN GYM) into a format compatible with stable-baselines3\n",
        "##, a popular library for reinforcement learning.\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBpWscLvDkOL"
      },
      "source": [
        "# Train Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3Dw2faxDjsH"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
        "if_using_a2c = True\n",
        "if_using_ddpg = False\n",
        "if_using_ppo =  False\n",
        "if_using_td3 = False\n",
        "if_using_sac = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv4piHG8D-__"
      },
      "source": [
        "## A2C Model\n",
        "\n",
        "The code above and below provide a healthy framework to add different agent types for training within the same notebook. For this I'll only be training an a2c model, but may add ddpg, ppo, and td3 in later iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrhYo_0ADwL9",
        "outputId": "4a32a9ea-8cb4-411c-cf80-31ad782b7b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "if if_using_a2c:\n",
        "  #setting up logger\n",
        "  tmp_path = RESULTS_DIR + '/a2c'\n",
        "  new_logger = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_a2c.set_logger(new_logger)\n",
        "  # - \"stdout\": Logs will be printed to the console.\n",
        "# - \"csv\": Logs will be saved in CSV format, useful for later analysis.\n",
        "# - \"tensorboard\": Logs will be compatible with TensorBoard for visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CT6vhWZD4K7",
        "outputId": "b08b563c-0b3e-4234-c020-30f8acfc2e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 155         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 40896       |\n",
            "|    policy_loss        | 4.41        |\n",
            "|    reward             | -0.71258926 |\n",
            "|    std                | 1.24        |\n",
            "|    value_loss         | 0.66        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 137       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 40996     |\n",
            "|    policy_loss        | -3.16     |\n",
            "|    reward             | -3.837431 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 0.512     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 150       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.00108   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 41096     |\n",
            "|    policy_loss        | -135      |\n",
            "|    reward             | 4.8525796 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 137       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 157       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 41196     |\n",
            "|    policy_loss        | -48.9     |\n",
            "|    reward             | 1.8745649 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 19.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 161        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 15         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 41296      |\n",
            "|    policy_loss        | 183        |\n",
            "|    reward             | -18.387823 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 312        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 157        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 41396      |\n",
            "|    policy_loss        | 53.2       |\n",
            "|    reward             | 0.17643291 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 17.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 155       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 41496     |\n",
            "|    policy_loss        | -77.5     |\n",
            "|    reward             | -8.057799 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 41.9      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 157          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 25           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -12.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 41596        |\n",
            "|    policy_loss        | 27.6         |\n",
            "|    reward             | -0.046346877 |\n",
            "|    std                | 1.23         |\n",
            "|    value_loss         | 6.34         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 160        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 41696      |\n",
            "|    policy_loss        | 28.1       |\n",
            "|    reward             | -1.1161196 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 6.1        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 162       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 41796     |\n",
            "|    policy_loss        | 32.9      |\n",
            "|    reward             | -9.060269 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 7.93      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 157      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | 0.000104 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 41896    |\n",
            "|    policy_loss        | -250     |\n",
            "|    reward             | 7.154317 |\n",
            "|    std                | 1.23     |\n",
            "|    value_loss         | 371      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 158        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.54      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 41996      |\n",
            "|    policy_loss        | -47.3      |\n",
            "|    reward             | 0.14736299 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 13.3       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 40         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 42096      |\n",
            "|    policy_loss        | 47.5       |\n",
            "|    reward             | -5.1543994 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 39.8       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 161      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | 9.41e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 42196    |\n",
            "|    policy_loss        | 41.3     |\n",
            "|    reward             | 2.7256   |\n",
            "|    std                | 1.23     |\n",
            "|    value_loss         | 11.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 160       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 42296     |\n",
            "|    policy_loss        | 14.5      |\n",
            "|    reward             | 2.5761368 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 1.97      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 157       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 50        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0498    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 42396     |\n",
            "|    policy_loss        | 5.73      |\n",
            "|    reward             | 1.5809975 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 0.627     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 158       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 53        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.000528  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 42496     |\n",
            "|    policy_loss        | -136      |\n",
            "|    reward             | 11.453376 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 132       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 160       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 42596     |\n",
            "|    policy_loss        | -0.415    |\n",
            "|    reward             | 2.9346309 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 2.05      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 161        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 58         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 42696      |\n",
            "|    policy_loss        | -42.2      |\n",
            "|    reward             | -0.5343583 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 22.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 62         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 42796      |\n",
            "|    policy_loss        | 14.9       |\n",
            "|    reward             | 0.22333379 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 3.35       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 158       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 42896     |\n",
            "|    policy_loss        | 7.51      |\n",
            "|    reward             | 1.5900548 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 8.68      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 68        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 42996     |\n",
            "|    policy_loss        | 13.4      |\n",
            "|    reward             | -9.620907 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 24.3      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 160         |\n",
            "|    iterations         | 2300        |\n",
            "|    time_elapsed       | 71          |\n",
            "|    total_timesteps    | 11500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 43096       |\n",
            "|    policy_loss        | -1.13e+03   |\n",
            "|    reward             | -0.27274576 |\n",
            "|    std                | 1.24        |\n",
            "|    value_loss         | 6.07e+03    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 161        |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.0145     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 43196      |\n",
            "|    policy_loss        | 42.7       |\n",
            "|    reward             | 0.34749943 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 13.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.112    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 43296     |\n",
            "|    policy_loss        | -57.5     |\n",
            "|    reward             | 0.4665151 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 17.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0785    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 43396     |\n",
            "|    policy_loss        | 4.07      |\n",
            "|    reward             | 2.1820693 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 0.597     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 160         |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 84          |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -0.0037     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 43496       |\n",
            "|    policy_loss        | -22.7       |\n",
            "|    reward             | -0.37137538 |\n",
            "|    std                | 1.24        |\n",
            "|    value_loss         | 9.58        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 160       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0138    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 43596     |\n",
            "|    policy_loss        | -15.2     |\n",
            "|    reward             | 5.0291653 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 9.14      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 160       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 43696     |\n",
            "|    policy_loss        | -18.6     |\n",
            "|    reward             | 0.7111446 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 2.37      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 158       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 94        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 43796     |\n",
            "|    policy_loss        | -3.02     |\n",
            "|    reward             | 1.2281259 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 0.51      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 97          |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0.191       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 43896       |\n",
            "|    policy_loss        | -15.5       |\n",
            "|    reward             | -0.62881494 |\n",
            "|    std                | 1.24        |\n",
            "|    value_loss         | 2.95        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 160        |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 99         |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.0349     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 43996      |\n",
            "|    policy_loss        | -24.1      |\n",
            "|    reward             | -1.7943596 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 32.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 160        |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 102        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 44096      |\n",
            "|    policy_loss        | 60.1       |\n",
            "|    reward             | -5.6369147 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 45.1       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 106         |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 44196       |\n",
            "|    policy_loss        | -41.7       |\n",
            "|    reward             | -0.71063626 |\n",
            "|    std                | 1.24        |\n",
            "|    value_loss         | 34.3        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 158         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 110         |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0.0203      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 44296       |\n",
            "|    policy_loss        | 93.3        |\n",
            "|    reward             | -0.06646544 |\n",
            "|    std                | 1.24        |\n",
            "|    value_loss         | 69.6        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 112       |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0196    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 44396     |\n",
            "|    policy_loss        | -51.8     |\n",
            "|    reward             | 1.7221503 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 29.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 115        |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.361     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 44496      |\n",
            "|    policy_loss        | 72.4       |\n",
            "|    reward             | -3.8848903 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 24.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 160       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 118       |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 44596     |\n",
            "|    policy_loss        | -13.9     |\n",
            "|    reward             | 1.2560853 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 2.27      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 158        |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 123        |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 44696      |\n",
            "|    policy_loss        | -71.4      |\n",
            "|    reward             | 0.19578348 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 38.9       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 158      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 125      |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 44796    |\n",
            "|    policy_loss        | 35.2     |\n",
            "|    reward             | 4.311301 |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 13.1     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 128        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.528     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 44896      |\n",
            "|    policy_loss        | -14.5      |\n",
            "|    reward             | -0.3928323 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 4.5        |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 159          |\n",
            "|    iterations         | 4200         |\n",
            "|    time_elapsed       | 131          |\n",
            "|    total_timesteps    | 21000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | -0.043       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 44996        |\n",
            "|    policy_loss        | -158         |\n",
            "|    reward             | 0.0121063925 |\n",
            "|    std                | 1.25         |\n",
            "|    value_loss         | 160          |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 4300     |\n",
            "|    time_elapsed       | 134      |\n",
            "|    total_timesteps    | 21500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0.0737   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45096    |\n",
            "|    policy_loss        | -24.3    |\n",
            "|    reward             | 5.333303 |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 7.87     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 158      |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 138      |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45196    |\n",
            "|    policy_loss        | 5.08     |\n",
            "|    reward             | 4.703287 |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 19.3     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 141      |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45296    |\n",
            "|    policy_loss        | 212      |\n",
            "|    reward             | 2.316348 |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 247      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 144       |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 45396     |\n",
            "|    policy_loss        | 27.5      |\n",
            "|    reward             | 4.7665763 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 44.5      |\n",
            "-------------------------------------\n",
            "day: 2892, episode: 80\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 8263307.36\n",
            "total_reward: 7263307.36\n",
            "total_cost: 10925.92\n",
            "total_trades: 14047\n",
            "Sharpe: 0.989\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 147        |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 45496      |\n",
            "|    policy_loss        | -7.07      |\n",
            "|    reward             | -0.2594696 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 7.6        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 150        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0197    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 45596      |\n",
            "|    policy_loss        | -112       |\n",
            "|    reward             | -1.5452311 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 105        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 158       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 154       |\n",
            "|    total_timesteps    | 24500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 45696     |\n",
            "|    policy_loss        | -14.4     |\n",
            "|    reward             | 1.5037233 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 6.31      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 156       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 45796     |\n",
            "|    policy_loss        | -43.5     |\n",
            "|    reward             | -3.179261 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 14.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 159       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 45896     |\n",
            "|    policy_loss        | 41.7      |\n",
            "|    reward             | 1.5617609 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 24.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 162       |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 45996     |\n",
            "|    policy_loss        | -245      |\n",
            "|    reward             | 14.892722 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 534       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 158       |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 166       |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0052    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 46096     |\n",
            "|    policy_loss        | -30.7     |\n",
            "|    reward             | 0.5506949 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 6.07      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 169       |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 46196     |\n",
            "|    policy_loss        | -29.2     |\n",
            "|    reward             | 1.4363496 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 13.8      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 5500     |\n",
            "|    time_elapsed       | 172      |\n",
            "|    total_timesteps    | 27500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 46296    |\n",
            "|    policy_loss        | 17.7     |\n",
            "|    reward             | 2.727085 |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 8.34     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 175        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 46396      |\n",
            "|    policy_loss        | -45.8      |\n",
            "|    reward             | -11.715957 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 16.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 178        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 46496      |\n",
            "|    policy_loss        | -59.9      |\n",
            "|    reward             | -1.4316508 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 42.7       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 5800        |\n",
            "|    time_elapsed       | 182         |\n",
            "|    total_timesteps    | 29000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 46596       |\n",
            "|    policy_loss        | -10.9       |\n",
            "|    reward             | -0.06567896 |\n",
            "|    std                | 1.26        |\n",
            "|    value_loss         | 3.14        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 5900       |\n",
            "|    time_elapsed       | 185        |\n",
            "|    total_timesteps    | 29500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 46696      |\n",
            "|    policy_loss        | 17.6       |\n",
            "|    reward             | -0.5051555 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 6.18       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 187        |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0189     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 46796      |\n",
            "|    policy_loss        | 14.6       |\n",
            "|    reward             | -1.5639696 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 3.81       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 160        |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 190        |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 46896      |\n",
            "|    policy_loss        | -26.5      |\n",
            "|    reward             | -3.7099993 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 9.28       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 194        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 46996      |\n",
            "|    policy_loss        | 46.7       |\n",
            "|    reward             | -0.7979691 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 11.2       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 6300     |\n",
            "|    time_elapsed       | 197      |\n",
            "|    total_timesteps    | 31500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 47096    |\n",
            "|    policy_loss        | 13.2     |\n",
            "|    reward             | 13.02615 |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 28.6     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 200      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.1    |\n",
            "|    explained_variance | -0.00782 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 47196    |\n",
            "|    policy_loss        | 35       |\n",
            "|    reward             | 2.414931 |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 8.9      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 6500       |\n",
            "|    time_elapsed       | 203        |\n",
            "|    total_timesteps    | 32500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.00491   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 47296      |\n",
            "|    policy_loss        | -20.2      |\n",
            "|    reward             | -4.7764072 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 11.7       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 6600        |\n",
            "|    time_elapsed       | 206         |\n",
            "|    total_timesteps    | 33000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -0.151      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 47396       |\n",
            "|    policy_loss        | -18.8       |\n",
            "|    reward             | -0.04858082 |\n",
            "|    std                | 1.26        |\n",
            "|    value_loss         | 3.64        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 6700       |\n",
            "|    time_elapsed       | 210        |\n",
            "|    total_timesteps    | 33500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 47496      |\n",
            "|    policy_loss        | -357       |\n",
            "|    reward             | -10.995462 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 1.01e+03   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 6800      |\n",
            "|    time_elapsed       | 213       |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 47596     |\n",
            "|    policy_loss        | -220      |\n",
            "|    reward             | 3.2231004 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 280       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 215         |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 47696       |\n",
            "|    policy_loss        | -182        |\n",
            "|    reward             | -0.40172532 |\n",
            "|    std                | 1.26        |\n",
            "|    value_loss         | 250         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 160        |\n",
            "|    iterations         | 7000       |\n",
            "|    time_elapsed       | 218        |\n",
            "|    total_timesteps    | 35000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.211     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 47796      |\n",
            "|    policy_loss        | 81.9       |\n",
            "|    reward             | 0.44186166 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 45.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 7100      |\n",
            "|    time_elapsed       | 221       |\n",
            "|    total_timesteps    | 35500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 47896     |\n",
            "|    policy_loss        | 38.9      |\n",
            "|    reward             | 2.6324441 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 12.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 7200      |\n",
            "|    time_elapsed       | 225       |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.0256    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 47996     |\n",
            "|    policy_loss        | -153      |\n",
            "|    reward             | 0.5133746 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 159       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 7300      |\n",
            "|    time_elapsed       | 229       |\n",
            "|    total_timesteps    | 36500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 48096     |\n",
            "|    policy_loss        | 27.1      |\n",
            "|    reward             | -4.762859 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 12.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 7400       |\n",
            "|    time_elapsed       | 232        |\n",
            "|    total_timesteps    | 37000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 48196      |\n",
            "|    policy_loss        | 205        |\n",
            "|    reward             | -12.078231 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 403        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 7500       |\n",
            "|    time_elapsed       | 234        |\n",
            "|    total_timesteps    | 37500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 48296      |\n",
            "|    policy_loss        | 228        |\n",
            "|    reward             | -15.980033 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 366        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 158       |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 239       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 48396     |\n",
            "|    policy_loss        | -57.3     |\n",
            "|    reward             | 1.6073835 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 23.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 158        |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 242        |\n",
            "|    total_timesteps    | 38500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 48496      |\n",
            "|    policy_loss        | -62.5      |\n",
            "|    reward             | -0.4781345 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 23.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 7800      |\n",
            "|    time_elapsed       | 244       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 48596     |\n",
            "|    policy_loss        | -44.7     |\n",
            "|    reward             | 2.6090193 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 14.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 247       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 48696     |\n",
            "|    policy_loss        | 108       |\n",
            "|    reward             | 13.602748 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 109       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 250        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 48796      |\n",
            "|    policy_loss        | -246       |\n",
            "|    reward             | -3.6684783 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 468        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 158       |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 254       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 48896     |\n",
            "|    policy_loss        | 55.4      |\n",
            "|    reward             | 22.526672 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 161       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 8200        |\n",
            "|    time_elapsed       | 257         |\n",
            "|    total_timesteps    | 41000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 48996       |\n",
            "|    policy_loss        | 18.9        |\n",
            "|    reward             | -0.26287222 |\n",
            "|    std                | 1.25        |\n",
            "|    value_loss         | 2.72        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 260       |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 49096     |\n",
            "|    policy_loss        | -14.4     |\n",
            "|    reward             | -4.114361 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 5.58      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 263         |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 49196       |\n",
            "|    policy_loss        | 31          |\n",
            "|    reward             | -0.26171976 |\n",
            "|    std                | 1.26        |\n",
            "|    value_loss         | 7.62        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 8500       |\n",
            "|    time_elapsed       | 266        |\n",
            "|    total_timesteps    | 42500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 49296      |\n",
            "|    policy_loss        | -127       |\n",
            "|    reward             | 0.83372194 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 112        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 158        |\n",
            "|    iterations         | 8600       |\n",
            "|    time_elapsed       | 270        |\n",
            "|    total_timesteps    | 43000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 49396      |\n",
            "|    policy_loss        | 184        |\n",
            "|    reward             | -36.146217 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 292        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 273       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 49496     |\n",
            "|    policy_loss        | 1.84      |\n",
            "|    reward             | 0.8742109 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 1.51      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 275        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0012    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 49596      |\n",
            "|    policy_loss        | -33.5      |\n",
            "|    reward             | -0.6533395 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 8.33       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 159          |\n",
            "|    iterations         | 8900         |\n",
            "|    time_elapsed       | 278          |\n",
            "|    total_timesteps    | 44500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 49696        |\n",
            "|    policy_loss        | -18          |\n",
            "|    reward             | -0.109162405 |\n",
            "|    std                | 1.27         |\n",
            "|    value_loss         | 5.83         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 282        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 49796      |\n",
            "|    policy_loss        | 5.83       |\n",
            "|    reward             | 0.15428993 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 41.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 285       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 49896     |\n",
            "|    policy_loss        | 91.9      |\n",
            "|    reward             | 2.0957499 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 38        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 288       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 49996     |\n",
            "|    policy_loss        | -64.5     |\n",
            "|    reward             | -0.911917 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 115       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 9300        |\n",
            "|    time_elapsed       | 291         |\n",
            "|    total_timesteps    | 46500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0.403       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 50096       |\n",
            "|    policy_loss        | -73.5       |\n",
            "|    reward             | -0.15980285 |\n",
            "|    std                | 1.26        |\n",
            "|    value_loss         | 26          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 294       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 50196     |\n",
            "|    policy_loss        | 80.5      |\n",
            "|    reward             | -3.070876 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 38.5      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 158          |\n",
            "|    iterations         | 9500         |\n",
            "|    time_elapsed       | 298          |\n",
            "|    total_timesteps    | 47500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.1        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 50296        |\n",
            "|    policy_loss        | -40.2        |\n",
            "|    reward             | -0.019575344 |\n",
            "|    std                | 1.26         |\n",
            "|    value_loss         | 15.4         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 9600      |\n",
            "|    time_elapsed       | 301       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 50396     |\n",
            "|    policy_loss        | -26.9     |\n",
            "|    reward             | 1.3159598 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 10.9      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 159         |\n",
            "|    iterations         | 9700        |\n",
            "|    time_elapsed       | 304         |\n",
            "|    total_timesteps    | 48500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 50496       |\n",
            "|    policy_loss        | 30.9        |\n",
            "|    reward             | -0.37354425 |\n",
            "|    std                | 1.26        |\n",
            "|    value_loss         | 14.1        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 9800      |\n",
            "|    time_elapsed       | 307       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 50596     |\n",
            "|    policy_loss        | -47.5     |\n",
            "|    reward             | 16.643698 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 204       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 310       |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.000462 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 50696     |\n",
            "|    policy_loss        | 15.2      |\n",
            "|    reward             | 1.8418106 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 2.28      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 314        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.00214    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 50796      |\n",
            "|    policy_loss        | 9.24       |\n",
            "|    reward             | -0.7778259 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 1.24       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 316       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 50896     |\n",
            "|    policy_loss        | -21.7     |\n",
            "|    reward             | 1.4402015 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 4.58      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 319       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 50996     |\n",
            "|    policy_loss        | 114       |\n",
            "|    reward             | 2.8420186 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 70.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 10300      |\n",
            "|    time_elapsed       | 322        |\n",
            "|    total_timesteps    | 51500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.00173    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 51096      |\n",
            "|    policy_loss        | -123       |\n",
            "|    reward             | -1.0469923 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 139        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 10400     |\n",
            "|    time_elapsed       | 326       |\n",
            "|    total_timesteps    | 52000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 51196     |\n",
            "|    policy_loss        | -174      |\n",
            "|    reward             | 52.896854 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 3.31e+03  |\n",
            "-------------------------------------\n",
            "day: 2892, episode: 90\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 13338882.67\n",
            "total_reward: 12338882.67\n",
            "total_cost: 10004.22\n",
            "total_trades: 13343\n",
            "Sharpe: 1.168\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 10500     |\n",
            "|    time_elapsed       | 329       |\n",
            "|    total_timesteps    | 52500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 51296     |\n",
            "|    policy_loss        | 75.5      |\n",
            "|    reward             | 2.4546337 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 39        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 159        |\n",
            "|    iterations         | 10600      |\n",
            "|    time_elapsed       | 332        |\n",
            "|    total_timesteps    | 53000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0124     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 51396      |\n",
            "|    policy_loss        | -27.1      |\n",
            "|    reward             | -0.6117747 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 8.26       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 10700     |\n",
            "|    time_elapsed       | 335       |\n",
            "|    total_timesteps    | 53500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 51496     |\n",
            "|    policy_loss        | 36.7      |\n",
            "|    reward             | -6.967888 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 20.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 159       |\n",
            "|    iterations         | 10800     |\n",
            "|    time_elapsed       | 337       |\n",
            "|    total_timesteps    | 54000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 51596     |\n",
            "|    policy_loss        | -66.3     |\n",
            "|    reward             | -4.098603 |\n",
            "|    std                | 1.27      |\n",
            "|    value_loss         | 38.7      |\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_a2c=agent.train_model(model=model_a2c,tb_log_name='a2c',total_timesteps=54000) if if_using_a2c else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-5pDMVwEbzN",
        "outputId": "43ff15de-467e-49fd-af35-43787fee8bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'trained_models/content/drive/My Drive/financial project' does not exist. Will create it.\n",
            "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
          ]
        }
      ],
      "source": [
        "trained_a2c.save(TRAINED_MODEL_DIR + \"/content/drive/My Drive/financial project/agent_a2c\") if if_using_a2c else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOuY-8BQwm53"
      },
      "source": [
        "# Consider Joining the Newsletter\n",
        "Stay Notified of New Videos and Code\n",
        "\n",
        "https://witty-motivator-1414.ck.page/acb393f729"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}